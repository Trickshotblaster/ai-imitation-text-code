# -*- coding: utf-8 -*-
"""ChatModelInference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N5aECj58SJ7yhvfl6ZZ5ElNCgM8X3ZjD
"""

API_TOKEN = "HUGGINGFACE_API_TOKEN_HERE"

from huggingface_hub.inference_api import InferenceApi

inference = InferenceApi(repo_id="HuggingFaceH4/zephyr-7b-beta", token=API_TOKEN)
prompt = "user1: hey\nuser2: wassup\nuser1: not much, hbu?\n"
result = inference(inputs=prompt)[0]['generated_text'][len(prompt):]
result = result[: result[len(prompt)-1:].find("\n")]
result

def prompt(history, user=None):
  inference = InferenceApi(repo_id="HuggingFaceH4/zephyr-7b-beta", token=API_TOKEN)
  prompt = history
  result = inference(inputs=prompt)[0]['generated_text'][len(prompt):]
  result = result[: result[len(prompt)-1:].find("\n")]
  if user and result.find(user) != None:
    return result[len(user)+2:]
  else:
    return False
hist = "user1: hey\nuser2: wassup\nuser1: not much, hbu?\n"
prompt(hist, user="user2")